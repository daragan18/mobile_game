{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = pd.read_csv('/mnt/HC_Volume_18315164/home-jupyter/jupyter-maksim-daragan-mxh-056d6/shared/problem1-reg_data.csv')\n",
    "auth_data = pd.read_csv('/mnt/HC_Volume_18315164/home-jupyter/jupyter-maksim-daragan-mxh-056d6/shared/problem1-auth_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data[['reg_ts', 'uid']] = reg_data['reg_ts;uid'].str.split(';', expand=True)\n",
    "auth_data[['auth_ts', 'uid']] = auth_data['auth_ts;uid'].str.split(';', expand=True)\n",
    "#создаём новый столбец для удобного отображения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.drop(columns=['reg_ts;uid'], inplace=True)\n",
    "auth_data.drop(columns=['auth_ts;uid'], inplace=True)\n",
    "#удаляем лишний столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['reg_time'] = pd.to_datetime(reg_data['reg_ts'], unit='s', utc=True).dt.date\n",
    "auth_data['auth_time'] = pd.to_datetime(auth_data['auth_ts'], unit='s', utc=True).dt.date\n",
    "#преобразуем количество секунд с начала эпохи Unix в дату, оставив только дни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data['reg_time'] = pd.to_datetime(reg_data['reg_time'])\n",
    "auth_data['auth_time'] = pd.to_datetime(auth_data['auth_time'])\n",
    "#переводим даты в формат datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_df = pd.merge(reg_data, auth_data, on='uid')\n",
    "#объединяем датафреймы в один"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_df.drop(columns=['reg_ts', 'auth_ts'], inplace=True)\n",
    "#убираем лишние колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_df['reg_time'] = pd.to_datetime(union_df['reg_time'])\n",
    "union_df['auth_time'] = pd.to_datetime(union_df['auth_time'])\n",
    "#переводим даты в формат datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_retention(auth_data, reg_data):\n",
    "     union_df['days_since_registration'] = (union_df['auth_time'] - union_df['reg_time']).dt.days\n",
    "     retention = union_df.groupby('days_since_registration')['uid'].nunique().reset_index()   \n",
    "     retention.columns = ['days_since_registration', 'retained_users']\n",
    "        \n",
    "     return retention   \n",
    "#прописываем функцию для подсчёта retention игроков (по дням от даты регистрации игрока)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      days_since_registration  retained_users\n",
      "0                           0         1000000\n",
      "1                           1           20071\n",
      "2                           2           40997\n",
      "3                           3           46338\n",
      "4                           4           52258\n",
      "...                       ...             ...\n",
      "5911                     7716               1\n",
      "5912                     7720               1\n",
      "5913                     7721               1\n",
      "5914                     7727               1\n",
      "5915                     7729               1\n",
      "\n",
      "[5916 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "retention_result = daily_retention(auth_data, reg_data)\n",
    "print(retention_result)\n",
    "#вычисляем retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cohort_retention(reg_data, auth_data):         \n",
    "  \n",
    "    merged_data = pd.merge(reg_data, auth_data, on='uid', how='left')\n",
    "    #Объединяем данные о регистрации и авторизации\n",
    "    \n",
    "    merged_data['days_since_registration'] = (merged_data['auth_time'] - merged_data['reg_time']).dt.days\n",
    "    #Вычисляем количество дней с момента регистрации\n",
    "    \n",
    "    merged_data = merged_data[merged_data['days_since_registration'] >= 0]\n",
    "    #Фильтруем только те записи, где авторизация произошла после регистрации\n",
    "    \n",
    "    cohort_data = merged_data.groupby(['reg_time', 'days_since_registration'])['uid'].nunique().reset_index()\n",
    "    cohort_data.columns = ['reg_date', 'days_since_registration', 'retention_count']\n",
    "    #Группируем по дате регистрации и количеству дней с момента регистрации\n",
    "    \n",
    "    cohort_pivot = cohort_data.pivot(index='reg_date', columns='days_since_registration', values='retention_count').fillna(0)\n",
    "    #Создаем сводную таблицу для удобства анализа\n",
    "    \n",
    "    return cohort_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_since_registration    0     1     2     3     4     5     6     7     \\\n",
      "reg_date                                                                    \n",
      "1998-11-18                  1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1999-07-22                  1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
      "2000-01-13                  1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2000-05-28                  1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2000-09-16                  1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "...                         ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "2020-09-19               1634.0  30.0  58.0  77.0  57.0   0.0   0.0   0.0   \n",
      "2020-09-20               1636.0  40.0  71.0  39.0   0.0   0.0   0.0   0.0   \n",
      "2020-09-21               1638.0  31.0  49.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2020-09-22               1641.0  14.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2020-09-23               1048.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "days_since_registration  8     9     ...  7701  7704  7706  7709  7712  7716  \\\n",
      "reg_date                             ...                                       \n",
      "1998-11-18                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1999-07-22                0.0   1.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   \n",
      "2000-01-13                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2000-05-28                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2000-09-16                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "...                       ...   ...  ...   ...   ...   ...   ...   ...   ...   \n",
      "2020-09-19                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2020-09-20                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2020-09-21                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2020-09-22                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2020-09-23                0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "days_since_registration  7720  7721  7727  7729  \n",
      "reg_date                                         \n",
      "1998-11-18                0.0   0.0   0.0   0.0  \n",
      "1999-07-22                1.0   1.0   1.0   1.0  \n",
      "2000-01-13                0.0   0.0   0.0   0.0  \n",
      "2000-05-28                0.0   0.0   0.0   0.0  \n",
      "2000-09-16                0.0   0.0   0.0   0.0  \n",
      "...                       ...   ...   ...   ...  \n",
      "2020-09-19                0.0   0.0   0.0   0.0  \n",
      "2020-09-20                0.0   0.0   0.0   0.0  \n",
      "2020-09-21                0.0   0.0   0.0   0.0  \n",
      "2020-09-22                0.0   0.0   0.0   0.0  \n",
      "2020-09-23                0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5110 rows x 5916 columns]\n"
     ]
    }
   ],
   "source": [
    "cohort_results = calculate_cohort_retention(reg_data, auth_data)\n",
    "\n",
    "print(cohort_results)\n",
    "#Выводим результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика ARPU (Average Revenue Per User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df = pd.read_csv('/mnt/HC_Volume_18315164/home-jupyter/jupyter-maksim-daragan-mxh-056d6/final_project_da/Проект_1_Задание_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df[['user_id', 'revenue', 'testgroup']] = ab_df['user_id;revenue;testgroup'].str.split(';', expand=True)\n",
    "#делаем датафрейм красивым и читаемым, разделяя столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df.drop(columns=['user_id;revenue;testgroup'], inplace=True)\n",
    "#удаляем лишние столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df['revenue'] = ab_df['revenue'].astype(int)\n",
    "#преобразуем значения столбца revenue в целочисленное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = ab_df[ab_df['testgroup'] == 'a'] \n",
    "test = ab_df[ab_df['testgroup'] == 'b'] \n",
    "#делим датафрейм на тестовую и контрольную группу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_arpu = control['revenue'].sum() / len(control)\n",
    "test_arpu = test['revenue'].sum() / len(test)\n",
    "#считаем ARPU для тестовой и контрольной группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(control['revenue'], test['revenue'], equal_var=False)\n",
    "#проводим t-тест для того, чтобы узнать, являются ли наши различия статистически значимыми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "#обозначаем уровень значимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value < alpha:\n",
    "    difference = True\n",
    "else:\n",
    "    difference = False\n",
    "#проверяем, является ли разница статистически значимой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая группа: control\n"
     ]
    }
   ],
   "source": [
    "if difference and test_arpu > control_arpu:\n",
    "    best_group = 'test'\n",
    "else:\n",
    "    best_group = 'control'\n",
    "\n",
    "print(f'Лучшая группа: {best_group}')\n",
    "#выводим результаты для выявления лучшей группы на основании ARPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика ARPPU (Average Revenue Per Paying User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_ab_df = ab_df[ab_df['revenue'] > 0]\n",
    "#выделяем в датафрейме только платящих пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_control = pay_ab_df[pay_ab_df['testgroup'] == 'a'] \n",
    "pay_test = pay_ab_df[pay_ab_df['testgroup'] == 'b'] \n",
    "#делим датафрейм на тестовую и контрольную группу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_arppu = pay_control['revenue'].sum() / len(pay_control)\n",
    "test_arppu = pay_test['revenue'].sum() / len(pay_test)\n",
    "#считаем ARPPU для тестовой и контрольной группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(pay_control['revenue'], pay_test['revenue'], equal_var=False)\n",
    "#проводим t-тест для того, чтобы узнать, являются ли наши различия статистически значимыми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value < alpha:\n",
    "    difference_pay = True\n",
    "else:\n",
    "    difference_pay = False\n",
    "#проверяем, является ли разница статистически значимой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая группа: control\n"
     ]
    }
   ],
   "source": [
    "if difference_pay and test_arppu > control_arppu:\n",
    "    best_group_pay = 'test'\n",
    "else:\n",
    "    best_group_pay = 'control'\n",
    "\n",
    "print(f'Лучшая группа: {best_group_pay}')\n",
    "#выводим результаты для выявления лучшей группы на основании ARPPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика Conversion Rate (Конверсия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_pay_users = 1928\n",
    "test_pay_users = 1805\n",
    "#обозначаем количество платящих пользователей в тестовой и контрольной группах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_total_users = 202103\n",
    "test_total_users = 202667\n",
    "#обозначаем общее количество пользователей в тестовой и контрольной группах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_conversion = (control_pay_users / control_total_users) * 100\n",
    "test_conversion = (test_pay_users / test_total_users) * 100\n",
    "#считаем конверсию для тестовой и контрольной группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay = [control_pay_users, test_pay_users]\n",
    "total = [control_total_users, test_total_users]\n",
    "z_stat, p_value = proportions_ztest(pay, total)\n",
    "#проводим z-тест для пропорций, чтобы проверить, есть ли статистически значимая разница в конверсии между группами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_conversion = p_value < alpha\n",
    "#проверяем, является ли разница статистически значимой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая группа: control\n"
     ]
    }
   ],
   "source": [
    "if difference_conversion and test_conversion > control_conversion:\n",
    "    best_group_conv = 'test'\n",
    "else:\n",
    "    best_group_conv = 'control'\n",
    "\n",
    "print(f'Лучшая группа: {best_group_conv}')\n",
    "#выводим результаты для выявления лучшей группы на основании Conversion Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: набор предложений в контрольной группе можно считать лучшим на основании метрик ARPU и Conversion Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В игре Plants & Gardens каждый месяц проводятся тематические события, ограниченные по времени. В них игроки могут получить уникальные предметы для сада и персонажей, дополнительные монеты или бонусы. Для получения награды требуется пройти ряд уровней за определенное время. С помощью каких метрик можно оценить результаты последнего прошедшего события?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные метрики для оценки результатов прошедшего события:\n",
    "    1. Общее количество пользователей, принявших участие в событии: метрика нужна для понимания интереса и привлекательности\n",
    "        ивента.\n",
    "    2. Процент завершения события: метрика позволяет оценить вовлечённость пользователей в ивент.\n",
    "    3. Среднее время прохождения: метрика позволяет оценить, насколько хорошо сбалансированы уровни по времени и сложности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, в другом событии мы усложнили механику событий так, что при каждой неудачной попытке выполнения уровня игрок будет откатываться на несколько уровней назад. Изменится ли набор метрик оценки результата? Если да, то как?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При усложнении механики я бы оставил предыдущие метрики, так как они являются ключевыми при оценке результата, но при этом добавил к ним новые:\n",
    "    1. Количество откатов: метрика позволяет оценить, насколько часто игроки совершают неудачные попытки.\n",
    "    2. Процент неудачных попыток: метрика позволяет понять, насколько сложными стали уровни.\n",
    "    3. Среднее время на каждый уровень: метрика позволяет понять, как усложнение механики влияет на общее время прохождения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
